# NLP_Transformers
Dans ce répertoire , nous avons testé, implémenté les différentes archtitectures Transformers(BERT/DistilBert/Roberta). 
L'approche de rédcution de dimensionnalité des modèles transformers a été téstée également avec les algortihmes de réduction de dimension tel que :
- Truncated Svd
- les Auto encodeurs
- les VAE
- Méthode de réduction de dimension proposée dans le papier:"Whitening Sentence Representations for Better Semantics and Faster Retrieval"
